{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from langchain.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import ToolMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from pandas.core.frame import DataFrame\n",
    "from pandas.core.series import Series\n",
    "import json\n",
    "import importlib\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass('Password: ')\n",
    "api_key = \"sk-pzmVDXe1-rxgtV34fEob57Owp9b7Z7_k-jYKmFaguDT3BlbkFJXR835WsPGSV7P_sjJXS2QGOJBIxgW5wSzwqExklvAA\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_function_generation_chain(csv_file_path_list, LLM_model, function_name):\n",
    "    df_dict = {}\n",
    "    df_info_list = []\n",
    "    buffer = StringIO()\n",
    "    cur = 1\n",
    "    for file_path in csv_file_path_list:\n",
    "        df = pd.read_csv(file_path, delimiter=',')\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        print(f\"Read the file {file_name}!\")\n",
    "        df.info(buf=buffer)\n",
    "        info_lines = buffer.getvalue().splitlines()\n",
    "        trimmed_info = '\\n'.join(info_lines[1:-2])\n",
    "        df_name = f\"csv_{cur}\"\n",
    "        cur += 1\n",
    "        df_info_list.append((df_name, trimmed_info))\n",
    "        buffer.truncate(0)\n",
    "        buffer.seek(0)\n",
    "        df_dict[df_name] = df.copy()\n",
    "        print(f\"{df_name} : {file_path}\")\n",
    "\n",
    "    df_template = \"\"\"```\n",
    "    {df_name}: \n",
    "    >>> {df_info}\n",
    "    ```\"\"\"\n",
    "\n",
    "    df_context = \"\\n\\n\".join(\n",
    "        df_template.format(df_name=df_name, df_info=df_info)\n",
    "        for df_name, df_info in df_info_list\n",
    "    )\n",
    "\n",
    "    tool = PythonAstREPLTool(locals=df_dict)\n",
    "    llm_with_tools = LLM_model.bind_tools([tool], tool_choice=tool.name)\n",
    "    parser = JsonOutputKeyToolsParser(key_name=tool.name, first_tool_only=True)\n",
    "    df_context = df_context.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    # Modify the system message with clearer instructions if necessary\n",
    "    system = f\"\"\"You have access to several pandas DataFrames. The following information contains the structure (column names and types) for each DataFrame:\n",
    "    {df_context}\n",
    "\n",
    "    Based on a user's request about the data, generate Python code that uses only built-in Python libraries, pandas. The code must be valid, complete, and functional.\n",
    "\n",
    "    Here are the key requirements:\n",
    "    1. Include all necessary import statements at the beginning of the code.\n",
    "    2. Ensure the code handles potential column name or index errors by carefully checking the DataFrame's structure.\n",
    "    3. Apply any necessary data preprocessing steps to handle missing data, incorrect data types, or any other common issues that could arise in the data. Pay special attention to ensuring that the data types are correct and consistent across columns to avoid type-related errors. Unify the data type if necessary\n",
    "    4. Ensure the intermediate state dataframe is stored in memory, if necessary, for future processing steps.\n",
    "    5. Return only the Python code—no explanations, comments, or extra text.\n",
    "    6. Wrap all the operations into a function called '{function_name}' whose input is a string called '社員番号' and a dict called df_dict same as dataframe name and dataframe passed above, and output is a dataframe and return it.'\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", system), (\"human\", \"{question}\")])\n",
    "\n",
    "    chain_until_parser = (prompt | llm_with_tools | parser)  # noqa\n",
    "    return chain_until_parser, df_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the file calc_data.csv!\n",
      "csv_1 : /Users/formaideveloper/LLM_excel/テスト用データ/other_1/calc_data.csv\n"
     ]
    }
   ],
   "source": [
    "file_path_1 = '/Users/formaideveloper/LLM_excel/テスト用データ/other_1/calc_data.csv'\n",
    "chain, df_dict = create_function_generation_chain([file_path_1], llm, \"function_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"'社員番号'が与えられている場合、次のように列を見つける：部門、就業規則、出勤日数、総出勤時間数。\"\n",
    "res = chain.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./function_1.py\", 'w') as f:\n",
    "    f.write(res[\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function function_1 at 0x7fa68cccf520>\n"
     ]
    }
   ],
   "source": [
    "func = getattr(importlib.import_module(\"function_1\"), \"function_1\")\n",
    "print(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             部門        就業規則区分  出勤日数  勤務時間合計\n",
      "0  エグゼクティブ　オフィス  正社員_管理監督者_本社   0.0     NaN\n"
     ]
    }
   ],
   "source": [
    "print(func(\"854430\", df_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = getattr(importlib.import_module(\"generated_functions.function_1\"), \"function_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
